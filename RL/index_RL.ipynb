{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 7>DELE ST1504 CA2 Part B: Reinforcement Learning </font>\n",
    "<hr>\n",
    "<font size = 4>\n",
    "Name: Lee Hong Yi<br>\n",
    "Admin No: 2223010<br>\n",
    "Class: DAAA/FT/2B/07<br>\n",
    "</font>\n",
    "<hr>\n",
    "\n",
    "**Objective:**  \n",
    "Develop a model using a modified Deep Q-Network (DQN) architecture to balance a pendulum. The model should apply suitable torque to maintain the pendulum in an upright position. The primary focus is on demonstrating the effectiveness of the DQN in this context, with the possibility of exploring other reinforcement learning architectures after the successful implementation of DQN.\n",
    "\n",
    "**Background:**  \n",
    "Deep Q-Networks are a class of deep reinforcement learning algorithms that combine Q-Learning with deep neural networks. This project aims to apply DQN to the classic control problem of pendulum balancing, a benchmark challenge in the reinforcement learning field. The goal is to train a model that can learn the optimal strategy to keep the pendulum balanced by applying the correct amount of torque.\n",
    "\n",
    "**Key Features:** <br>\n",
    "Implement a modified version of the DQN algorithm to specifically address the dynamics of pendulum balancing, using the Pendulum environment from OpenAI Gym, which provides a standardized platform for testing the model's performance.\n",
    "\n",
    "**Output Specification:**  \n",
    "The output specification for this Deep Q-Network (DQN) project focused on balancing a pendulum entails the generation of control actions in the form of torque values, which are applied at each timestep to maintain the pendulum's upright position. These actions, derived from the model's learning process, will be complemented by performance metrics demonstrating the learning progression, such as episode duration, balance efficiency, and torque magnitude. Additionally, the model will provide visualizations of the pendulum's state and behavior over time, as well as detailed evaluation metrics like average reward per episode and loss over time. The final output includes the learned policy, represented either through model weights or a graphical depiction, showcasing the model's effectiveness in learning and applying the optimal strategy for pendulum balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
